{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import findspark\n",
    "import functools as ft\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import findspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import Evaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.dataframe\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName(\"ml_example\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import LinearSVCTrainingSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>_2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA</td>\n",
       "      <td>Katie Mettam</td>\n",
       "      <td>2013-07-13T13:27:39.441000</td>\n",
       "      <td>I love this song because we sing it at Camp al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>_2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI</td>\n",
       "      <td>Sabina Pearson-Smith</td>\n",
       "      <td>2013-07-13T13:14:30.021000</td>\n",
       "      <td>I love this song for two reasons: 1.it is abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>_2viQ_Qnc6_k_n_Bse9zVhJP8tJReZpo8uM2uZfnzDs</td>\n",
       "      <td>jeffrey jules</td>\n",
       "      <td>2013-07-13T12:09:31.188000</td>\n",
       "      <td>wow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>_2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0</td>\n",
       "      <td>Aishlin Maciel</td>\n",
       "      <td>2013-07-13T11:17:52.308000</td>\n",
       "      <td>Shakira u are so wiredo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>_2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA</td>\n",
       "      <td>Latin Bosch</td>\n",
       "      <td>2013-07-12T22:33:27.916000</td>\n",
       "      <td>Shakira is the best dancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID                AUTHOR  \\\n",
       "0     LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU             Julius NM   \n",
       "1     LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A           adam riyati   \n",
       "2     LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8      Evgeny Murashkin   \n",
       "3             z13jhp0bxqncu512g22wvzkasxmvvzjaz04       ElNino Melendez   \n",
       "4             z13fwbwp1oujthgqj04chlngpvzmtt3r3dw                GsMega   \n",
       "...                                           ...                   ...   \n",
       "1951  _2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA          Katie Mettam   \n",
       "1952  _2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI  Sabina Pearson-Smith   \n",
       "1953  _2viQ_Qnc6_k_n_Bse9zVhJP8tJReZpo8uM2uZfnzDs         jeffrey jules   \n",
       "1954  _2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0        Aishlin Maciel   \n",
       "1955  _2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA           Latin Bosch   \n",
       "\n",
       "                            DATE  \\\n",
       "0            2013-11-07T06:20:48   \n",
       "1            2013-11-07T12:37:15   \n",
       "2            2013-11-08T17:34:21   \n",
       "3            2013-11-09T08:28:43   \n",
       "4            2013-11-10T16:05:38   \n",
       "...                          ...   \n",
       "1951  2013-07-13T13:27:39.441000   \n",
       "1952  2013-07-13T13:14:30.021000   \n",
       "1953  2013-07-13T12:09:31.188000   \n",
       "1954  2013-07-13T11:17:52.308000   \n",
       "1955  2013-07-12T22:33:27.916000   \n",
       "\n",
       "                                                CONTENT  CLASS  \n",
       "0     Huh, anyway check out this you[tube] channel: ...      1  \n",
       "1     Hey guys check out my new channel and our firs...      1  \n",
       "2                just for test I have to say murdev.com      1  \n",
       "3      me shaking my sexy ass on my channel enjoy ^_^ ﻿      1  \n",
       "4               watch?v=vtaRGgvGtWQ   Check this out .﻿      1  \n",
       "...                                                 ...    ...  \n",
       "1951  I love this song because we sing it at Camp al...      0  \n",
       "1952  I love this song for two reasons: 1.it is abou...      0  \n",
       "1953                                                wow      0  \n",
       "1954                            Shakira u are so wiredo      0  \n",
       "1955                         Shakira is the best dancer      0  \n",
       "\n",
       "[1956 rows x 5 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "psy_df = pd.read_csv('data\\Youtube01-Psy.csv')\n",
    "katy_df = pd.read_csv('data\\Youtube02-KatyPerry.csv')\n",
    "lmfao_df = pd.read_csv('data\\Youtube03-LMFAO.csv')\n",
    "eminem_df = pd.read_csv('data\\Youtube04-Eminem.csv')\n",
    "shakira_df = pd.read_csv('data\\Youtube05-Shakira.csv')\n",
    "\n",
    "dataframes = [psy_df, katy_df, lmfao_df, eminem_df, shakira_df]\n",
    "\n",
    "main_df = ft.reduce(lambda left, right: pd.concat([left, right], axis=0, ignore_index=True), dataframes)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to Follow:-\n",
    "1. Remove Stopwords\n",
    "2. Remove emojis\n",
    "3. Remove punctuation\n",
    "4. Lemmatization\n",
    "5. Tokenization\n",
    "6. Scaling\n",
    "7. Implement Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1005\n",
       "0     951\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>I love this song because we sing it at Camp al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>I love this song for two reasons: 1.it is abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>wow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>Shakira u are so wiredo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>Shakira is the best dancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                CONTENT  CLASS\n",
       "0     Huh, anyway check out this you[tube] channel: ...      1\n",
       "1     Hey guys check out my new channel and our firs...      1\n",
       "2                just for test I have to say murdev.com      1\n",
       "3      me shaking my sexy ass on my channel enjoy ^_^ ﻿      1\n",
       "4               watch?v=vtaRGgvGtWQ   Check this out .﻿      1\n",
       "...                                                 ...    ...\n",
       "1951  I love this song because we sing it at Camp al...      0\n",
       "1952  I love this song for two reasons: 1.it is abou...      0\n",
       "1953                                                wow      0\n",
       "1954                            Shakira u are so wiredo      0\n",
       "1955                         Shakira is the best dancer      0\n",
       "\n",
       "[1956 rows x 2 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.drop(['COMMENT_ID', 'AUTHOR', 'DATE'], axis=1, inplace=True)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding single letters to the list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'b', 'c', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'n', 'p', 'q', 'r', 'u', 'v', 'w', 'x', 'z']\n"
     ]
    }
   ],
   "source": [
    "alphabet_list = list(string.ascii_lowercase)\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "for i in range(len(alphabet_list)):\n",
    "    if (alphabet_list[i] in stop_words):\n",
    "        continue\n",
    "    else:\n",
    "        stop_words.append(alphabet_list[i])\n",
    "        \n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuations and Random Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, text):\n",
    "    df[text] = df[text].str.lower()\n",
    "    df[text] = df[text].apply(lambda elem: re.sub(r'@[A-Za-z0-9]+', '', elem))              # Removing all @mentions\n",
    "    df[text] = df[text].apply(lambda elem: re.sub(r'https?:\\/\\/\\S+', '', elem))             # Removing all links\n",
    "    df[text] = df[text].apply(lambda elem: re.sub(r'#', '', elem))                          # Removing the hashtag symbol\n",
    "    df[text] = df[text].apply(lambda elem: re.sub(r\"([^0-9A-Za-z \\t])\", \"\", elem))          # Removing all non-alphanumeric symbols\n",
    "    df[text] = df[text].apply(lambda elem: re.sub(r\"\\w*\\d\\w*\", \"\", elem))                   # Removing all numbers\n",
    "    df[text] = df[text].apply(lambda elem: re.sub(r\"^\\d+\\w|^\\w+\\d+\\w|^\\w+\\d$\", \"\", elem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check out this youtube channel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test i have to say murdevcom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watchvvtarggvgtwq   check this out</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>i love this song because we sing it at camp al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>i love this song for two reasons  is about afr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>wow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>shakira u are so wiredo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>shakira is the best dancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                CONTENT  CLASS\n",
       "0            huh anyway check out this youtube channel       1\n",
       "1     hey guys check out my new channel and our firs...      1\n",
       "2                 just for test i have to say murdevcom      1\n",
       "3          me shaking my sexy ass on my channel enjoy        1\n",
       "4                   watchvvtarggvgtwq   check this out       1\n",
       "...                                                 ...    ...\n",
       "1951  i love this song because we sing it at camp al...      0\n",
       "1952  i love this song for two reasons  is about afr...      0\n",
       "1953                                                wow      0\n",
       "1954                            shakira u are so wiredo      0\n",
       "1955                         shakira is the best dancer      0\n",
       "\n",
       "[1956 rows x 2 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = clean_text(main_df, 'CONTENT')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check youtube channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check new channel first vid us  monke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test say murdevcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaking sexy ass channel enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watchvvtarggvgtwq   check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hey check new website site kids stuff kidsmedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>subscribe channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>turned mute soon came wanted check  views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>check channel funny videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shouldd check channel tell next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hey subscribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>started reading stop subscribe  within one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>subscribe like comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>please like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hello like gaming art videos scientific experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>im checking views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>edm apparel company dedicated bringing music i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>think  millions views come people wanted  chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>subscribe channel people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>show auburn pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>checking views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>check channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>marketglory  comstrategygameandrijamatf earn r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hey guys im  yr old music producer make chiptu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>check im kyle rap yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dont even watch anymore come check  billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>subscribe free android games apps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>everyone please come check newest song memorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>came check views goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sub channel reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>check dubstep song fireball made fruity loops ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>billioncoming soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dafuq korean song big usa mean support  korean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>check channel please listen best music ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sub  sub please like comment want succesfull y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>hey everyone started first yt channel would g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>projects effects music foto web sites another ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>youtubecodytolleson awesome videos ill subscri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>like roblox minecraft world warcraft  mario su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>subscribe ill subscribe must like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>come follow watch stream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>like raw talent raw lyrics straight real hip h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>subscribe   channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>views pls comment view count next hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>go check views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>thumbs checked video see hw views got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>plz subscribe channel subscribe back xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>check back often help reach  views avoid watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>video get  billion people checking  hit  billi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>like  facebookpage chance win iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>get gwar play  superbowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pls follow channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>hi guys check youtube channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>subscribe like videos minecraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>great game check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>subscribe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              CONTENT\n",
       "0                   huh anyway check youtube channel \n",
       "1   hey guys check new channel first vid us  monke...\n",
       "2                                  test say murdevcom\n",
       "3                    shaking sexy ass channel enjoy  \n",
       "4                          watchvvtarggvgtwq   check \n",
       "5   hey check new website site kids stuff kidsmedi...\n",
       "6                                  subscribe channel \n",
       "7           turned mute soon came wanted check  views\n",
       "8                          check channel funny videos\n",
       "9                     shouldd check channel tell next\n",
       "10                                      hey subscribe\n",
       "11   started reading stop subscribe  within one da...\n",
       "12                                                   \n",
       "13                             subscribe like comment\n",
       "14                                       please like \n",
       "15  hello like gaming art videos scientific experi...\n",
       "16                                  im checking views\n",
       "17                                                   \n",
       "18                                                   \n",
       "19  edm apparel company dedicated bringing music i...\n",
       "20  think  millions views come people wanted  chec...\n",
       "21                           subscribe channel people\n",
       "22                                 show auburn pride \n",
       "23                                     checking views\n",
       "24                                      check channel\n",
       "25  marketglory  comstrategygameandrijamatf earn r...\n",
       "26  hey guys im  yr old music producer make chiptu...\n",
       "27                            check im kyle rap yeah \n",
       "28        dont even watch anymore come check  billion\n",
       "29                 subscribe free android games apps \n",
       "30  everyone please come check newest song memorie...\n",
       "31                           came check views goodbye\n",
       "32                                sub channel reason \n",
       "33  check dubstep song fireball made fruity loops ...\n",
       "34                                 billioncoming soon\n",
       "35  dafuq korean song big usa mean support  korean...\n",
       "36        check channel please listen best music ever\n",
       "37  sub  sub please like comment want succesfull y...\n",
       "38   hey everyone started first yt channel would g...\n",
       "39  projects effects music foto web sites another ...\n",
       "40  youtubecodytolleson awesome videos ill subscri...\n",
       "41  like roblox minecraft world warcraft  mario su...\n",
       "42               subscribe ill subscribe must like   \n",
       "43                           come follow watch stream\n",
       "44  like raw talent raw lyrics straight real hip h...\n",
       "45                                subscribe   channel\n",
       "46             views pls comment view count next hour\n",
       "47                                                   \n",
       "48                                    go check views \n",
       "49              thumbs checked video see hw views got\n",
       "50            plz subscribe channel subscribe back xx\n",
       "51  check back often help reach  views avoid watch...\n",
       "52  video get  billion people checking  hit  billi...\n",
       "53              like  facebookpage chance win iphone \n",
       "54                        get gwar play  superbowl   \n",
       "55                                pls follow channel \n",
       "56                      hi guys check youtube channel\n",
       "57                    subscribe like videos minecraft\n",
       "58                                   great game check\n",
       "59                                          subscribe"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(df, text):\n",
    "    ABC = list((df[text]))\n",
    "    clean_lst = []\n",
    "    for i in range(ABC.__len__()):\n",
    "        result_words = [word for word in ABC[i].split(' ') if word not in stop_words]\n",
    "        str_result = ' '.join(result_words)\n",
    "        clean_lst.append(str_result)\n",
    "        \n",
    "    cleaner_df = pd.DataFrame(clean_lst, columns=['CONTENT'])\n",
    "    \n",
    "    return cleaner_df\n",
    "\n",
    "cleaner_df = remove_stopwords(clean_df, 'CONTENT')\n",
    "cleaner_df.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check youtube channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check new channel first vid us  monke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test say murdevcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaking sexy ass channel enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watchvvtarggvgtwq   check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>love song sing camp time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>love song two reasons  africa  born beautiful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>shakira wiredo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>shakira best dancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                CONTENT\n",
       "0                     huh anyway check youtube channel \n",
       "1     hey guys check new channel first vid us  monke...\n",
       "2                                    test say murdevcom\n",
       "3                      shaking sexy ass channel enjoy  \n",
       "4                            watchvvtarggvgtwq   check \n",
       "...                                                 ...\n",
       "1951                           love song sing camp time\n",
       "1952  love song two reasons  africa  born beautiful ...\n",
       "1953                                                wow\n",
       "1954                                     shakira wiredo\n",
       "1955                                shakira best dancer\n",
       "\n",
       "[1956 rows x 1 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner_df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "# cleaner_df.to_csv('data/temp_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check youtube channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guy check new channel first vid u monkey i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test say murdevcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaking sexy as channel enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watchvvtarggvgtwq check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>love song sing camp time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>love song two reason africa born beautiful sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>shakira wiredo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>shakira best dancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                CONTENT\n",
       "0                      huh anyway check youtube channel\n",
       "1     hey guy check new channel first vid u monkey i...\n",
       "2                                    test say murdevcom\n",
       "3                         shaking sexy as channel enjoy\n",
       "4                               watchvvtarggvgtwq check\n",
       "...                                                 ...\n",
       "1951                           love song sing camp time\n",
       "1952  love song two reason africa born beautiful sou...\n",
       "1953                                                wow\n",
       "1954                                     shakira wiredo\n",
       "1955                                shakira best dancer\n",
       "\n",
       "[1956 rows x 1 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        'V': wordnet.VERB,\n",
    "        'N': wordnet.NOUN,\n",
    "        'J': wordnet.ADJ,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "    \n",
    "    return tag_dict.get(tag)\n",
    "\n",
    "def lem_df(df, text):\n",
    "    lst_sent = list(df[text])\n",
    "    lem_lst = []\n",
    "    for i in range(len(lst_sent)):\n",
    "        input = nltk.word_tokenize(lst_sent[i])\n",
    "        result_words = [lemmatizer.lemmatize(word) for word in input]\n",
    "        str_result = ' '.join(result_words)\n",
    "        lem_lst.append(str_result)\n",
    "        \n",
    "    cleanest_df = pd.DataFrame(lem_lst, columns=['CONTENT'])\n",
    "    return cleanest_df\n",
    "\n",
    "lemmatized_df = lem_df(cleaner_df, 'CONTENT')\n",
    "lemmatized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_df(df, col_name):\n",
    "    sentences = []\n",
    "    \n",
    "    length = df[col_name].__len__()\n",
    "    \n",
    "    for i in range(length):\n",
    "        sentences.append(df[col_name][i])\n",
    "        \n",
    "    tokenizer = Tokenizer(num_words=3400, oov_token='<00V>')\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    word_index = tokenizer.word_index\n",
    "    # print(word_index)\n",
    "    \n",
    "    # Sequencing\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    sequences = pad_sequences(sequences, padding='post', maxlen=16)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "\n",
    "    \n",
    "tokenized_seq = tokenize_df(lemmatized_df, 'CONTENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633</td>\n",
       "      <td>835</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>433</td>\n",
       "      <td>40</td>\n",
       "      <td>634</td>\n",
       "      <td>18</td>\n",
       "      <td>634</td>\n",
       "      <td>376</td>\n",
       "      <td>1306</td>\n",
       "      <td>169</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1307</td>\n",
       "      <td>208</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1309</td>\n",
       "      <td>209</td>\n",
       "      <td>377</td>\n",
       "      <td>10</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1310</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>564</td>\n",
       "      <td>269</td>\n",
       "      <td>337</td>\n",
       "      <td>757</td>\n",
       "      <td>105</td>\n",
       "      <td>969</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1     2    3    4    5    6    7    8    9    10   11  12  13  \\\n",
       "0      633  835     2    8   10    0    0    0    0    0     0    0   0   0   \n",
       "1        2   14    10   82  433   40  634   18  634  376  1306  169   5  17   \n",
       "2     1307  208  1308    0    0    0    0    0    0    0     0    0   0   0   \n",
       "3     1309  209   377   10  210    0    0    0    0    0     0    0   0   0   \n",
       "4     1310    2     0    0    0    0    0    0    0    0     0    0   0   0   \n",
       "...    ...  ...   ...  ...  ...  ...  ...  ...  ...  ...   ...  ...  ..  ..   \n",
       "1951     9    4   290    1   29    0    0    0    0    0     0    0   0   0   \n",
       "1952     9    4   564  269  337  757  105  969  337    0     0    0   0   0   \n",
       "1953   123    0     0    0    0    0    0    0    0    0     0    0   0   0   \n",
       "1954    55    1     0    0    0    0    0    0    0    0     0    0   0   0   \n",
       "1955    55   23     1    0    0    0    0    0    0    0     0    0   0   0   \n",
       "\n",
       "      14  15  CLASS  \n",
       "0      0   0      1  \n",
       "1      6   7      1  \n",
       "2      0   0      1  \n",
       "3      0   0      1  \n",
       "4      0   0      1  \n",
       "...   ..  ..    ...  \n",
       "1951   0   0      0  \n",
       "1952   0   0      0  \n",
       "1953   0   0      0  \n",
       "1954   0   0      0  \n",
       "1955   0   0      0  \n",
       "\n",
       "[1956 rows x 17 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train = pd.DataFrame(tokenized_seq)\n",
    "tokenized_train = tokenized_train.join(main_df['CLASS'])\n",
    "tokenized_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1005\n",
      "0    1005\n",
      "Name: CLASS, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633</td>\n",
       "      <td>835</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>433</td>\n",
       "      <td>40</td>\n",
       "      <td>634</td>\n",
       "      <td>18</td>\n",
       "      <td>634</td>\n",
       "      <td>376</td>\n",
       "      <td>1306</td>\n",
       "      <td>169</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1307</td>\n",
       "      <td>208</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1309</td>\n",
       "      <td>209</td>\n",
       "      <td>377</td>\n",
       "      <td>10</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1310</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>160</td>\n",
       "      <td>417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>284</td>\n",
       "      <td>131</td>\n",
       "      <td>113</td>\n",
       "      <td>317</td>\n",
       "      <td>131</td>\n",
       "      <td>171</td>\n",
       "      <td>157</td>\n",
       "      <td>130</td>\n",
       "      <td>343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>125</td>\n",
       "      <td>244</td>\n",
       "      <td>673</td>\n",
       "      <td>39</td>\n",
       "      <td>155</td>\n",
       "      <td>104</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>658</td>\n",
       "      <td>171</td>\n",
       "      <td>157</td>\n",
       "      <td>130</td>\n",
       "      <td>343</td>\n",
       "      <td>171</td>\n",
       "      <td>157</td>\n",
       "      <td>130</td>\n",
       "      <td>343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>3</td>\n",
       "      <td>739</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2010 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1     2    3    4    5    6    7    8    9    10   11  12  13  \\\n",
       "0      633  835     2    8   10    0    0    0    0    0     0    0   0   0   \n",
       "1        2   14    10   82  433   40  634   18  634  376  1306  169   5  17   \n",
       "2     1307  208  1308    0    0    0    0    0    0    0     0    0   0   0   \n",
       "3     1309  209   377   10  210    0    0    0    0    0     0    0   0   0   \n",
       "4     1310    2     0    0    0    0    0    0    0    0     0    0   0   0   \n",
       "...    ...  ...   ...  ...  ...  ...  ...  ...  ...  ...   ...  ...  ..  ..   \n",
       "2005    24   41   160  417    0    0    0    0    0    0     0    0   0   0   \n",
       "2006   284  131   113  317  131  171  157  130  343    0     0    0   0   0   \n",
       "2007   125  244   673   39  155  104   83    0    0    0     0    0   0   0   \n",
       "2008   658  171   157  130  343  171  157  130  343    0     0    0   0   0   \n",
       "2009     3  739   262    0    0    0    0    0    0    0     0    0   0   0   \n",
       "\n",
       "      14  15  CLASS  \n",
       "0      0   0      1  \n",
       "1      6   7      1  \n",
       "2      0   0      1  \n",
       "3      0   0      1  \n",
       "4      0   0      1  \n",
       "...   ..  ..    ...  \n",
       "2005   0   0      0  \n",
       "2006   0   0      0  \n",
       "2007   0   0      0  \n",
       "2008   0   0      0  \n",
       "2009   0   0      0  \n",
       "\n",
       "[2010 rows x 17 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train['CLASS'].value_counts()\n",
    "\n",
    "train_majority = tokenized_train[tokenized_train.CLASS == 1]\n",
    "train_minority = tokenized_train[tokenized_train.CLASS == 0]\n",
    "\n",
    "minority_upsampled = resample(train_minority, replace=True, n_samples=train_majority.__len__(), random_state=123)\n",
    "minority_upsampled['CLASS'].value_counts()\n",
    "\n",
    "train_upsampled = pd.concat([train_majority, minority_upsampled], ignore_index=True)\n",
    "print(train_upsampled['CLASS'].value_counts())\n",
    "train_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nscaler = StandardScaler()\\nscaler.fit(train_upsampled.drop('CLASS', axis=1))\\nscaled_feature = scaler.transform(train_upsampled.drop('CLASS', axis=1))\\nscaled_df = pd.DataFrame(scaled_feature, columns = train_upsampled.columns[:-1])\\n# scaled_df = pd.concat([scaled_df, train_upsampled['CLASS']], axis=1, ignore_index=True)\\nscaled_df  = scaled_df.join(train_upsampled['CLASS'])\\nscaled_df \""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_upsampled.drop('CLASS', axis=1))\n",
    "scaled_feature = scaler.transform(train_upsampled.drop('CLASS', axis=1))\n",
    "scaled_df = pd.DataFrame(scaled_feature, columns = train_upsampled.columns[:-1])\n",
    "# scaled_df = pd.concat([scaled_df, train_upsampled['CLASS']], axis=1, ignore_index=True)\n",
    "scaled_df  = scaled_df.join(train_upsampled['CLASS'])\n",
    "scaled_df \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" final_train = pd.DataFrame(X_train).join(y_train)\\nfinal_test = pd.DataFrame(X_test).join(y_test)\\nprint(final_train['CLASS'].value_counts())\\nprint(final_test['CLASS'].value_counts()) \""
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" final_train = pd.DataFrame(X_train).join(y_train)\n",
    "final_test = pd.DataFrame(X_test).join(y_test)\n",
    "print(final_train['CLASS'].value_counts())\n",
    "print(final_test['CLASS'].value_counts()) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upsampled.to_csv('data/clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- 1: integer (nullable = true)\n",
      " |-- 2: integer (nullable = true)\n",
      " |-- 3: integer (nullable = true)\n",
      " |-- 4: integer (nullable = true)\n",
      " |-- 5: integer (nullable = true)\n",
      " |-- 6: integer (nullable = true)\n",
      " |-- 7: integer (nullable = true)\n",
      " |-- 8: integer (nullable = true)\n",
      " |-- 9: integer (nullable = true)\n",
      " |-- 10: integer (nullable = true)\n",
      " |-- 11: integer (nullable = true)\n",
      " |-- 12: integer (nullable = true)\n",
      " |-- 13: integer (nullable = true)\n",
      " |-- 14: integer (nullable = true)\n",
      " |-- 15: integer (nullable = true)\n",
      " |-- CLASS: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = spark.read.csv('data/clean_data.csv', header=True, inferSchema=True)\n",
    "training_data.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Features Array\n",
    "# The VectorAssembler makes a single vector from all the feature columns to be used as feature input\n",
    "\n",
    "feature_cols = training_data.columns[:-1]\n",
    "\n",
    "vect_assmebler = VectorAssembler(inputCols=feature_cols, outputCol='Features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+---+----+----+---+----+----+----+----+---+---+---+---+----+-----+--------------------+\n",
      "|   0|   1|   2|  3|   4|   5|  6|   7|   8|   9|  10| 11| 12| 13| 14|  15|CLASS|            Features|\n",
      "+----+----+----+---+----+----+---+----+----+----+----+---+---+---+---+----+-----+--------------------+\n",
      "| 633| 835|   2|  8|  10|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2,3,4],[...|\n",
      "|   2|  14|  10| 82| 433|  40|634|  18| 634| 376|1306|169|  5| 17|  6|   7|    1|[2.0,14.0,10.0,82...|\n",
      "|1307| 208|1308|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2],[1307...|\n",
      "|1309| 209| 377| 10| 210|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2,3,4],[...|\n",
      "|1310|   2|   0|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1],[1310.0...|\n",
      "|  22|   2|  14| 72| 170| 268|378|1311| 236|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2,3,4,5,...|\n",
      "|   7|  10|   0|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1],[7.0,10...|\n",
      "|   2|  10| 136|  3|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2,3],[2....|\n",
      "|1312|   2|  10|176| 211|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2,3,4],[...|\n",
      "|  22|   7|   0|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1],[22.0,7...|\n",
      "| 118| 146| 177|  7| 837|  30| 83| 253|1313| 434| 636| 43|637|524|  7| 119|    1|[118.0,146.0,177....|\n",
      "|   0|   0|   0|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|          (16,[],[])|\n",
      "|   7|   5|  17|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2],[7.0,...|\n",
      "|   6|   5|   0|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1],[6.0,5.0])|\n",
      "|   6|   2|  10|  7| 838| 118|196| 155| 839|  49|1318| 88|  2|838| 84| 299|    1|[6.0,2.0,10.0,7.0...|\n",
      "|   0|   0|   0|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|          (16,[],[])|\n",
      "|   0|   0|   0|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|          (16,[],[])|\n",
      "| 212|1326| 212|842|1327|1328| 95|  40| 147|1329|  56|843|436| 48|170|1330|    1|[212.0,1326.0,212...|\n",
      "|   7|  10|  20|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2],[7.0,...|\n",
      "| 437|1331|1332|  0|   0|   0|  0|   0|   0|   0|   0|  0|  0|  0|  0|   0|    1|(16,[0,1,2],[437....|\n",
      "+----+----+----+---+----+----+---+----+----+----+----+---+---+---+---+----+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_w_features = vect_assmebler.transform(training_data)\n",
    "data_w_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Features|CLASS|\n",
      "+--------------------+-----+\n",
      "|(16,[0,1,2,3,4],[...|    1|\n",
      "|[2.0,14.0,10.0,82...|    1|\n",
      "|(16,[0,1,2],[1307...|    1|\n",
      "|(16,[0,1,2,3,4],[...|    1|\n",
      "|(16,[0,1],[1310.0...|    1|\n",
      "|(16,[0,1,2,3,4,5,...|    1|\n",
      "|(16,[0,1],[7.0,10...|    1|\n",
      "|(16,[0,1,2,3],[2....|    1|\n",
      "|(16,[0,1,2,3,4],[...|    1|\n",
      "|(16,[0,1],[22.0,7...|    1|\n",
      "|[118.0,146.0,177....|    1|\n",
      "|          (16,[],[])|    1|\n",
      "|(16,[0,1,2],[7.0,...|    1|\n",
      "|(16,[0,1],[6.0,5.0])|    1|\n",
      "|[6.0,2.0,10.0,7.0...|    1|\n",
      "|          (16,[],[])|    1|\n",
      "|          (16,[],[])|    1|\n",
      "|[212.0,1326.0,212...|    1|\n",
      "|(16,[0,1,2],[7.0,...|    1|\n",
      "|(16,[0,1,2],[437....|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating Final Dataframe to feed into the model\n",
    "\n",
    "final_data = data_w_features.select('Features', 'CLASS')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7,0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.999989144174332, -0.999989144174332]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.999989144174332, -0.999989144174332]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.999989144174332, -0.999989144174332]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.999989144174332, -0.999989144174332]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.999989144174332, -0.999989144174332]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Features  CLASS  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "\n",
       "                             rawPrediction  prediction  \n",
       "0  [0.999989144174332, -0.999989144174332]         0.0  \n",
       "1  [0.999989144174332, -0.999989144174332]         0.0  \n",
       "2  [0.999989144174332, -0.999989144174332]         0.0  \n",
       "3  [0.999989144174332, -0.999989144174332]         0.0  \n",
       "4  [0.999989144174332, -0.999989144174332]         0.0  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(featuresCol='Features', labelCol='CLASS')\n",
    "\n",
    "columns = ['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6', '_c7', '_c8', '_c9', '_c10', '_c11', '_c12', '_c13', '_c14', '_c15', '_c16', '_c17', '_c18', '_c19', '_c20', '_c21', '_c22', '_c23', '_c24', '_c25']\n",
    "\n",
    "# Fitting the model\n",
    "lsvc_model = lsvc.fit(train_data)\n",
    "\n",
    "pred = lsvc_model.transform(test_data)\n",
    "predDF = pred.toPandas()\n",
    "predDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy:  0.5704584040747029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\", labelCol='CLASS', predictionCol='prediction')\n",
    "acc = evaluator.evaluate(pred)\n",
    "print(\"Prediction Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' lsvc_sum = LinearSVCTrainingSummary()\\nprint(lsvc_sum.accuracy(lsvc_model)) '"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" lsvc_sum = LinearSVCTrainingSummary()\n",
    "print(lsvc_sum.accuracy(lsvc_model)) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f73e532cbd269d1026df71fd8a305c34d1349d3ece4a0a5c075e0ca7a6a1c7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
